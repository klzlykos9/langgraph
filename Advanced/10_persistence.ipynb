{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565bb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76352444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d4a2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = 'gemini-2.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bce62912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic : str\n",
    "    joke : str\n",
    "    explanation : str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfefa816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "\n",
    "    prompt = f\"generate a joke on the topic {state['topic']}\"\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b742ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "\n",
    "    prompt = f'write an explanation for the joke -{state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "981ae2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explanation', generate_explanation)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f6da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000222548D2E90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178a7ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"',\n",
       " 'explanation': 'Of course! Here is an explanation of the joke.\\n\\n### The Breakdown of the Joke\\n\\nThis is a classic example of a **pun**. A pun is a form of wordplay that uses a word or phrase that has two different meanings, or that sounds like another word.\\n\\nHere\\'s how it works:\\n\\n1.  **The Original Phrase:** The joke plays on the common, polite greeting, \"**Nice to meet you.**\" This is what someone typically says when they are introduced to a new person.\\n\\n2.  **The Pun:** The punchline swaps the word \"**Nice**\" with \"**Slice**.\" These two words sound very similar, especially when said quickly.\\n\\n3.  **The Connection:** The word \"Slice\" is directly related to the characters in the joke—pepperoni and cheese.\\n    *   **Pepperoni** is almost always served in thin, round **slices**.\\n    *   **Cheese** is also very often cut into **slices** (for sandwiches, crackers, or pizza).\\n\\n### Putting It All Together\\n\\nThe joke creates a funny mental image of a slice of pepperoni being introduced to cheese (likely on a pizza). Instead of using the normal human greeting \"Nice to meet you,\" the pepperoni uses a greeting that is relevant to its own form—a slice.\\n\\nSo, the humor comes from the clever and silly substitution of \"Nice\" with \"Slice,\" making it a perfect, \"cheesy\" joke about pizza ingredients.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {'configurable': {'thread_id': \"1\"}}\n",
    "workflow.invoke({'topic':'pizza'}, config = config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deab682e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"', 'explanation': 'Of course! Here is an explanation of the joke.\\n\\n### The Breakdown of the Joke\\n\\nThis is a classic example of a **pun**. A pun is a form of wordplay that uses a word or phrase that has two different meanings, or that sounds like another word.\\n\\nHere\\'s how it works:\\n\\n1.  **The Original Phrase:** The joke plays on the common, polite greeting, \"**Nice to meet you.**\" This is what someone typically says when they are introduced to a new person.\\n\\n2.  **The Pun:** The punchline swaps the word \"**Nice**\" with \"**Slice**.\" These two words sound very similar, especially when said quickly.\\n\\n3.  **The Connection:** The word \"Slice\" is directly related to the characters in the joke—pepperoni and cheese.\\n    *   **Pepperoni** is almost always served in thin, round **slices**.\\n    *   **Cheese** is also very often cut into **slices** (for sandwiches, crackers, or pizza).\\n\\n### Putting It All Together\\n\\nThe joke creates a funny mental image of a slice of pepperoni being introduced to cheese (likely on a pizza). Instead of using the normal human greeting \"Nice to meet you,\" the pepperoni uses a greeting that is relevant to its own form—a slice.\\n\\nSo, the humor comes from the clever and silly substitution of \"Nice\" with \"Slice,\" making it a perfect, \"cheesy\" joke about pizza ingredients.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-f59e-6e23-8002-568d9735c481'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-16T07:23:36.695513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-6fdf-62f7-8001-ba2c31a0de30'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-6fdf-62f7-8001-ba2c31a0de30'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-16T07:23:22.670945+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-785b-6a06-8000-404d08b729f9'}}, tasks=(PregelTask(id='2a29ef48-06ed-c3ed-3b6f-68751fc9853d', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'Of course! Here is an explanation of the joke.\\n\\n### The Breakdown of the Joke\\n\\nThis is a classic example of a **pun**. A pun is a form of wordplay that uses a word or phrase that has two different meanings, or that sounds like another word.\\n\\nHere\\'s how it works:\\n\\n1.  **The Original Phrase:** The joke plays on the common, polite greeting, \"**Nice to meet you.**\" This is what someone typically says when they are introduced to a new person.\\n\\n2.  **The Pun:** The punchline swaps the word \"**Nice**\" with \"**Slice**.\" These two words sound very similar, especially when said quickly.\\n\\n3.  **The Connection:** The word \"Slice\" is directly related to the characters in the joke—pepperoni and cheese.\\n    *   **Pepperoni** is almost always served in thin, round **slices**.\\n    *   **Cheese** is also very often cut into **slices** (for sandwiches, crackers, or pizza).\\n\\n### Putting It All Together\\n\\nThe joke creates a funny mental image of a slice of pepperoni being introduced to cheese (likely on a pizza). Instead of using the normal human greeting \"Nice to meet you,\" the pepperoni uses a greeting that is relevant to its own form—a slice.\\n\\nSo, the humor comes from the clever and silly substitution of \"Nice\" with \"Slice,\" making it a perfect, \"cheesy\" joke about pizza ingredients.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-785b-6a06-8000-404d08b729f9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:22:56.717230+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-7830-62bb-bfff-ba0536148f5b'}}, tasks=(PregelTask(id='f9843951-2267-8282-8632-dddc8f5e0956', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-7830-62bb-bfff-ba0536148f5b'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-16T07:22:56.699434+00:00', parent_config=None, tasks=(PregelTask(id='bbfc7e03-b2ee-6e81-de89-9981966b1715', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))   # to check state history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'chowmin',\n",
       " 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way',\n",
       " 'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3 = {'configurable': {'thread_id': \"3\"}}\n",
    "workflow.invoke({'topic':'chowmin'}, config = config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way', 'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}, next=(), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-b633-6a9f-8002-07732bd1382b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-16T07:42:44.318030+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}, next=('generate_explanation',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-16T07:42:31.925480+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, tasks=(PregelTask(id='5ad2b988-b8a3-d3b0-c8dc-9cc87806c6f3', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin'}, next=('generate_joke',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:42:16.397961+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, tasks=(PregelTask(id='b4441ea7-85eb-23ea-9c8f-284ef4393d74', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-16T07:42:16.395806+00:00', parent_config=None, tasks=(PregelTask(id='06043ed2-2b68-98f0-c7bb-303d1430d132', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'chowmin'}),), interrupts=())]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62178b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f5c623b",
   "metadata": {},
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55691b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6f70380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"', 'explanation': 'Of course! Here is an explanation of the joke.\\n\\n### The Breakdown of the Joke\\n\\nThis is a classic example of a **pun**. A pun is a form of wordplay that uses a word or phrase that has two different meanings, or that sounds like another word.\\n\\nHere\\'s how it works:\\n\\n1.  **The Original Phrase:** The joke plays on the common, polite greeting, \"**Nice to meet you.**\" This is what someone typically says when they are introduced to a new person.\\n\\n2.  **The Pun:** The punchline swaps the word \"**Nice**\" with \"**Slice**.\" These two words sound very similar, especially when said quickly.\\n\\n3.  **The Connection:** The word \"Slice\" is directly related to the characters in the joke—pepperoni and cheese.\\n    *   **Pepperoni** is almost always served in thin, round **slices**.\\n    *   **Cheese** is also very often cut into **slices** (for sandwiches, crackers, or pizza).\\n\\n### Putting It All Together\\n\\nThe joke creates a funny mental image of a slice of pepperoni being introduced to cheese (likely on a pizza). Instead of using the normal human greeting \"Nice to meet you,\" the pepperoni uses a greeting that is relevant to its own form—a slice.\\n\\nSo, the humor comes from the clever and silly substitution of \"Nice\" with \"Slice,\" making it a perfect, \"cheesy\" joke about pizza ingredients.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-f59e-6e23-8002-568d9735c481'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-16T07:23:36.695513+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-6fdf-62f7-8001-ba2c31a0de30'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092ce0-6fdf-62f7-8001-ba2c31a0de30'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-16T07:23:22.670945+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-785b-6a06-8000-404d08b729f9'}}, tasks=(PregelTask(id='2a29ef48-06ed-c3ed-3b6f-68751fc9853d', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'Of course! Here is an explanation of the joke.\\n\\n### The Breakdown of the Joke\\n\\nThis is a classic example of a **pun**. A pun is a form of wordplay that uses a word or phrase that has two different meanings, or that sounds like another word.\\n\\nHere\\'s how it works:\\n\\n1.  **The Original Phrase:** The joke plays on the common, polite greeting, \"**Nice to meet you.**\" This is what someone typically says when they are introduced to a new person.\\n\\n2.  **The Pun:** The punchline swaps the word \"**Nice**\" with \"**Slice**.\" These two words sound very similar, especially when said quickly.\\n\\n3.  **The Connection:** The word \"Slice\" is directly related to the characters in the joke—pepperoni and cheese.\\n    *   **Pepperoni** is almost always served in thin, round **slices**.\\n    *   **Cheese** is also very often cut into **slices** (for sandwiches, crackers, or pizza).\\n\\n### Putting It All Together\\n\\nThe joke creates a funny mental image of a slice of pepperoni being introduced to cheese (likely on a pizza). Instead of using the normal human greeting \"Nice to meet you,\" the pepperoni uses a greeting that is relevant to its own form—a slice.\\n\\nSo, the humor comes from the clever and silly substitution of \"Nice\" with \"Slice,\" making it a perfect, \"cheesy\" joke about pizza ingredients.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-785b-6a06-8000-404d08b729f9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:22:56.717230+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-7830-62bb-bfff-ba0536148f5b'}}, tasks=(PregelTask(id='f9843951-2267-8282-8632-dddc8f5e0956', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-7830-62bb-bfff-ba0536148f5b'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-16T07:22:56.699434+00:00', parent_config=None, tasks=(PregelTask(id='bbfc7e03-b2ee-6e81-de89-9981966b1715', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f092cdf-785b-6a06-8000-404d08b729f9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:22:56.717230+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f092cdf-7830-62bb-bfff-ba0536148f5b'}}, tasks=(PregelTask(id='f9843951-2267-8282-8632-dddc8f5e0956', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'What did the pepperoni say to the cheese?\\n\\n\"Slice to meet you!\"'}),), interrupts=())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\": {\"thread_id\":\"1\", \"checkpoint_id\":\"1f092cdf-785b-6a06-8000-404d08b729f9\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84a0019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': \"Why did the mushroom get invited to all the pizza parties?\\n\\nBecause he's a *fun-gi* to be with\",\n",
       " 'explanation': 'Of course! Here is an explanation of the joke.\\n\\nThis is a classic pun, which means the humor comes from a play on words.\\n\\nHere\\'s the breakdown:\\n\\n1.  **The Sound-Alike:** The punchline \"fun-gi\" is meant to be heard as the phrase **\"fun guy.\"** Someone who is a \"fun guy\" is enjoyable to be around and would naturally be invited to parties.\\n\\n2.  **The Literal Meaning:** A mushroom is a type of **fungus**. The plural of fungus is **fungi**.\\n\\nSo, the joke cleverly combines these two meanings. The mushroom gets invited to parties because he\\'s a **\"fun guy\"** (a great personality), and the word used to describe this is **\"fun-gi\"** (his biological classification).\\n\\nThe joke is extra fitting because mushrooms are a common pizza topping, so it makes perfect sense for one to be at a pizza party in the first place'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\":\"1\", \"checkpoint_id\":\"1f092cdf-785b-6a06-8000-404d08b729f9\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way', 'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}, next=(), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-b633-6a9f-8002-07732bd1382b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-16T07:42:44.318030+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}, next=('generate_explanation',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-16T07:42:31.925480+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, tasks=(PregelTask(id='5ad2b988-b8a3-d3b0-c8dc-9cc87806c6f3', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin'}, next=('generate_joke',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:42:16.397961+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, tasks=(PregelTask(id='b4441ea7-85eb-23ea-9c8f-284ef4393d74', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-16T07:42:16.395806+00:00', parent_config=None, tasks=(PregelTask(id='06043ed2-2b68-98f0-c7bb-303d1430d132', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'chowmin'}),), interrupts=())]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92387dc7",
   "metadata": {},
   "source": [
    "## Updating State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '3',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f093058-d1a5-615e-8001-30a60db59fe8'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({\"configurable\": {\"thread_id\": \"3\", \"checkpoint_id\": \"1f092d0a-abef-6688-8000-5659dc54c993\" ,\"checkpoint_ns\":\"\" }}, {'topic': 'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ea975fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f093058-d1a5-615e-8001-30a60db59fe8'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2025-09-16T14:00:49.991678+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, tasks=(PregelTask(id='9e78ab2c-69cf-a1f8-3214-55ea987c7d15', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way', 'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}, next=(), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-b633-6a9f-8002-07732bd1382b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-16T07:42:44.318030+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin', 'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}, next=('generate_explanation',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0b-4004-6757-8001-2ead061d14a9'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-16T07:42:31.925480+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, tasks=(PregelTask(id='5ad2b988-b8a3-d3b0-c8dc-9cc87806c6f3', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'Of course! Here is a breakdown of the joke:\\n\\nThis joke is a classic **pun**, which is a form of wordplay that uses words with similar sounds but different meanings.\\n\\n1.  **The Setup:** \"Why did the chow mein get a job as a tour guide?\" This creates a silly scenario, making you wonder what a noodle dish could possibly do as a tour guide.\\n\\n2.  **The Punchline:** \"Because it was great at **chow-mein** people the way.\"\\n\\n3.  **The Pun Explained:** The phrase \"**chow-mein**\" is meant to sound just like the word \"**showing**.\"\\n\\nIf you replace the pun with the real word, the sentence becomes:\\n\\n\"Because it was great at **showing** people the way.\"\\n\\nAnd what is the main job of a tour guide? To **show** people the way. The humor comes from the unexpected and slightly goofy substitution of \"chow mein\" for \"showing.\"'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'chowmin'}, next=('generate_joke',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abef-6688-8000-5659dc54c993'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-16T07:42:16.397961+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, tasks=(PregelTask(id='b4441ea7-85eb-23ea-9c8f-284ef4393d74', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did the chow mein get a job as a tour guide?\\n\\nBecause it was great at **chow-mein** people the way'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f092d0a-abea-6255-bfff-a362f2cc4d3d'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-16T07:42:16.395806+00:00', parent_config=None, tasks=(PregelTask(id='06043ed2-2b68-98f0-c7bb-303d1430d132', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'chowmin'}),), interrupts=())]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0e325e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'samosa',\n",
       " 'joke': 'Why did the samosa get invited to all the parties?\\n\\nBecause he was a real snack with all the right angles',\n",
       " 'explanation': 'Of course! Here is a breakdown of the joke.\\n\\nThe humor in this joke comes from a **pun**, which plays on the double meanings of two key phrases in the punchline: \"**a real snack**\" and \"**all the right angles**.\"\\n\\nLet\\'s break it down:\\n\\n### 1. \"A real snack\"\\n\\n*   **Literal Meaning:** A samosa is, quite literally, a snack. It\\'s a savory pastry, a type of food you eat.\\n*   **Slang Meaning:** In modern slang, calling a person \"a snack\" is a compliment that means they are very attractive or good-looking.\\n\\nSo, the first part of the joke implies the samosa is popular because it\\'s both a delicious food item and an attractive \"person\" at the party.\\n\\n### 2. \"With all the right angles\"\\n\\n*   **Literal Meaning:** A samosa is famous for its distinct triangular or pyramid-like shape. It is physically made up of sharp corners and angles.\\n*   **Figurative Meaning:** The phrase \"to know all the angles\" means to be clever, savvy, and know the best way to handle a situation. In the context of being attractive, \"knowing your angles\" means knowing how to pose or present yourself to look your best.\\n\\n### Putting It All Together:\\n\\nThe joke personifies the samosa, treating it like a guest at a party. It\\'s invited everywhere because:\\n\\nIt\\'s **\"a real snack\"** (both a tasty food and an attractive person) who also has **\"all the right angles\"** (both a triangular shape and the cleverness/poise to be a great party guest).\\n\\nThe humor lies in the clever way these phrases perfectly describe both the physical food and the personality of a popular person.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\":{\"thread_id\": \"3\", \"chekcpoint_id\": \"1f093058-d1a5-615e-8001-30a60db59fe8\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20c0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab093a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9dbe744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: google-generativeai\n"
     ]
    }
   ],
   "source": [
    "!pip show google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a212eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f06a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e0e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbaf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df5cdbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\LangGraph\\part_1\\myenv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "011e7aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/gemini-1.5-pro-latest Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
      "                   'million tokens.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-pro-002 Model(name='models/gemini-1.5-pro-002',\n",
      "      base_model_id='',\n",
      "      version='002',\n",
      "      display_name='Gemini 1.5 Pro 002',\n",
      "      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
      "                   'supports up to 2 million tokens, released in September of 2024.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-pro Model(name='models/gemini-1.5-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
      "                   'supports up to 2 million tokens, released in May of 2024.'),\n",
      "      input_token_limit=2000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash-latest Model(name='models/gemini-1.5-flash-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
      "                   'across diverse tasks.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
      "                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash-002 Model(name='models/gemini-1.5-flash-002',\n",
      "      base_model_id='',\n",
      "      version='002',\n",
      "      display_name='Gemini 1.5 Flash 002',\n",
      "      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
      "                   'for scaling across diverse tasks, released in September of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash-8b Model(name='models/gemini-1.5-flash-8b',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B',\n",
      "      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
      "                   'Flash model, released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash-8b-001 Model(name='models/gemini-1.5-flash-8b-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B 001',\n",
      "      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
      "                   'Flash model, released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-1.5-flash-8b-latest Model(name='models/gemini-1.5-flash-8b-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash-8B Latest',\n",
      "      description=('Alias that points to the most recent production (non-experimental) release '\n",
      "                   'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
      "                   'released in October of 2024.'),\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.5-pro-preview-03-25 Model(name='models/gemini-2.5-pro-preview-03-25',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-03-25',\n",
      "      display_name='Gemini 2.5 Pro Preview 03-25',\n",
      "      description='Gemini 2.5 Pro Preview 03-25',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-preview-05-20 Model(name='models/gemini-2.5-flash-preview-05-20',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-05-20',\n",
      "      display_name='Gemini 2.5 Flash Preview 05-20',\n",
      "      description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash Model(name='models/gemini-2.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 2.5 Flash',\n",
      "      description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
      "                   'supports up to 1 million tokens, released in June of 2025.'),\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-lite-preview-06-17 Model(name='models/gemini-2.5-flash-lite-preview-06-17',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-06-17',\n",
      "      display_name='Gemini 2.5 Flash-Lite Preview 06-17',\n",
      "      description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-pro-preview-05-06 Model(name='models/gemini-2.5-pro-preview-05-06',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-05-06',\n",
      "      display_name='Gemini 2.5 Pro Preview 05-06',\n",
      "      description='Preview release (May 6th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-pro-preview-06-05 Model(name='models/gemini-2.5-pro-preview-06-05',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-06-05',\n",
      "      display_name='Gemini 2.5 Pro Preview',\n",
      "      description='Preview release (June 5th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-pro Model(name='models/gemini-2.5-pro',\n",
      "      base_model_id='',\n",
      "      version='2.5',\n",
      "      display_name='Gemini 2.5 Pro',\n",
      "      description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-exp Model(name='models/gemini-2.0-flash-exp',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash Experimental',\n",
      "      description='Gemini 2.0 Flash Experimental',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash Model(name='models/gemini-2.0-flash',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash',\n",
      "      description='Gemini 2.0 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-001 Model(name='models/gemini-2.0-flash-001',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash 001',\n",
      "      description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
      "                   'for scaling across diverse tasks, released in January of 2025.'),\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-exp-image-generation Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "      description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-lite-001 Model(name='models/gemini-2.0-flash-lite-001',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash-Lite 001',\n",
      "      description='Stable version of Gemini 2.0 Flash-Lite',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-lite Model(name='models/gemini-2.0-flash-lite',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash-Lite',\n",
      "      description='Gemini 2.0 Flash-Lite',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-preview-image-generation Model(name='models/gemini-2.0-flash-preview-image-generation',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash Preview Image Generation',\n",
      "      description='Gemini 2.0 Flash Preview Image Generation',\n",
      "      input_token_limit=32768,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-lite-preview-02-05 Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
      "      base_model_id='',\n",
      "      version='preview-02-05',\n",
      "      display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
      "      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-flash-lite-preview Model(name='models/gemini-2.0-flash-lite-preview',\n",
      "      base_model_id='',\n",
      "      version='preview-02-05',\n",
      "      display_name='Gemini 2.0 Flash-Lite Preview',\n",
      "      description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "models/gemini-2.0-pro-exp Model(name='models/gemini-2.0-pro-exp',\n",
      "      base_model_id='',\n",
      "      version='2.5-exp-03-25',\n",
      "      display_name='Gemini 2.0 Pro Experimental',\n",
      "      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-pro-exp-02-05 Model(name='models/gemini-2.0-pro-exp-02-05',\n",
      "      base_model_id='',\n",
      "      version='2.5-exp-03-25',\n",
      "      display_name='Gemini 2.0 Pro Experimental 02-05',\n",
      "      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-exp-1206 Model(name='models/gemini-exp-1206',\n",
      "      base_model_id='',\n",
      "      version='2.5-exp-03-25',\n",
      "      display_name='Gemini Experimental 1206',\n",
      "      description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-05-20',\n",
      "      display_name='Gemini 2.5 Flash Preview 05-20',\n",
      "      description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-thinking-exp Model(name='models/gemini-2.0-flash-thinking-exp',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-05-20',\n",
      "      display_name='Gemini 2.5 Flash Preview 05-20',\n",
      "      description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-thinking-exp-1219 Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
      "      base_model_id='',\n",
      "      version='2.5-preview-05-20',\n",
      "      display_name='Gemini 2.5 Flash Preview 05-20',\n",
      "      description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-preview-tts Model(name='models/gemini-2.5-flash-preview-tts',\n",
      "      base_model_id='',\n",
      "      version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
      "      display_name='Gemini 2.5 Flash Preview TTS',\n",
      "      description='Gemini 2.5 Flash Preview TTS',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=16384,\n",
      "      supported_generation_methods=['countTokens', 'generateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-pro-preview-tts Model(name='models/gemini-2.5-pro-preview-tts',\n",
      "      base_model_id='',\n",
      "      version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
      "      display_name='Gemini 2.5 Pro Preview TTS',\n",
      "      description='Gemini 2.5 Pro Preview TTS',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=16384,\n",
      "      supported_generation_methods=['countTokens', 'generateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/learnlm-2.0-flash-experimental Model(name='models/learnlm-2.0-flash-experimental',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='LearnLM 2.0 Flash Experimental',\n",
      "      description='LearnLM 2.0 Flash Experimental',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=32768,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3-1b-it Model(name='models/gemma-3-1b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3 1B',\n",
      "      description='',\n",
      "      input_token_limit=32768,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3-4b-it Model(name='models/gemma-3-4b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3 4B',\n",
      "      description='',\n",
      "      input_token_limit=32768,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3-12b-it Model(name='models/gemma-3-12b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3 12B',\n",
      "      description='',\n",
      "      input_token_limit=32768,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3-27b-it Model(name='models/gemma-3-27b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3 27B',\n",
      "      description='',\n",
      "      input_token_limit=131072,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3n-e4b-it Model(name='models/gemma-3n-e4b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3n E4B',\n",
      "      description='',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemma-3n-e2b-it Model(name='models/gemma-3n-e2b-it',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemma 3n E2B',\n",
      "      description='',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-lite Model(name='models/gemini-2.5-flash-lite',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 2.5 Flash-Lite',\n",
      "      description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['generateContent',\n",
      "                                    'countTokens',\n",
      "                                    'createCachedContent',\n",
      "                                    'batchGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-image-preview Model(name='models/gemini-2.5-flash-image-preview',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Nano Banana',\n",
      "      description='Gemini 2.5 Flash Preview Image',\n",
      "      input_token_limit=32768,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/embedding-001 Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/text-embedding-004 Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/gemini-embedding-exp-03-07 Model(name='models/gemini-embedding-exp-03-07',\n",
      "      base_model_id='',\n",
      "      version='exp-03-07',\n",
      "      display_name='Gemini Embedding Experimental 03-07',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/gemini-embedding-exp Model(name='models/gemini-embedding-exp',\n",
      "      base_model_id='',\n",
      "      version='exp-03-07',\n",
      "      display_name='Gemini Embedding Experimental',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=8192,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/gemini-embedding-001 Model(name='models/gemini-embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/aqa Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n",
      "models/imagen-3.0-generate-002 Model(name='models/imagen-3.0-generate-002',\n",
      "      base_model_id='',\n",
      "      version='002',\n",
      "      display_name='Imagen 3.0',\n",
      "      description='Vertex served Imagen 3.0 002 model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/imagen-4.0-generate-preview-06-06 Model(name='models/imagen-4.0-generate-preview-06-06',\n",
      "      base_model_id='',\n",
      "      version='01',\n",
      "      display_name='Imagen 4 (Preview)',\n",
      "      description='Vertex served Imagen 4.0 model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 Model(name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
      "      base_model_id='',\n",
      "      version='01',\n",
      "      display_name='Imagen 4 Ultra (Preview)',\n",
      "      description='Vertex served Imagen 4.0 ultra model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/imagen-4.0-generate-001 Model(name='models/imagen-4.0-generate-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Imagen 4',\n",
      "      description='Vertex served Imagen 4.0 model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/imagen-4.0-ultra-generate-001 Model(name='models/imagen-4.0-ultra-generate-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Imagen 4 Ultra',\n",
      "      description='Vertex served Imagen 4.0 ultra model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/imagen-4.0-fast-generate-001 Model(name='models/imagen-4.0-fast-generate-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Imagen 4 Fast',\n",
      "      description='Vertex served Imagen 4.0 Fast model',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predict'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/veo-2.0-generate-001 Model(name='models/veo-2.0-generate-001',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Veo 2',\n",
      "      description=('Vertex served Veo 2 model. Access to this model requires billing to be '\n",
      "                   'enabled on the associated Google Cloud Platform account. Please visit '\n",
      "                   'https://console.cloud.google.com/billing to enable it.'),\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predictLongRunning'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/veo-3.0-generate-preview Model(name='models/veo-3.0-generate-preview',\n",
      "      base_model_id='',\n",
      "      version='3.0',\n",
      "      display_name='Veo 3',\n",
      "      description='Veo 3 preview.',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predictLongRunning'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/veo-3.0-fast-generate-preview Model(name='models/veo-3.0-fast-generate-preview',\n",
      "      base_model_id='',\n",
      "      version='3.0',\n",
      "      display_name='Veo 3 fast',\n",
      "      description='Veo 3 fast preview.',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predictLongRunning'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/veo-3.0-generate-001 Model(name='models/veo-3.0-generate-001',\n",
      "      base_model_id='',\n",
      "      version='3.0',\n",
      "      display_name='Veo 3',\n",
      "      description='Veo 3 preview.',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predictLongRunning'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/veo-3.0-fast-generate-001 Model(name='models/veo-3.0-fast-generate-001',\n",
      "      base_model_id='',\n",
      "      version='3.0',\n",
      "      display_name='Veo 3 fast',\n",
      "      description='Veo 3 fast preview.',\n",
      "      input_token_limit=480,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['predictLongRunning'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog Model(name='models/gemini-2.5-flash-preview-native-audio-dialog',\n",
      "      base_model_id='',\n",
      "      version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19',\n",
      "      display_name='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
      "      description='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
      "      input_token_limit=131072,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog Model(name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog',\n",
      "      base_model_id='',\n",
      "      version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19',\n",
      "      display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
      "      description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
      "      input_token_limit=131072,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.0-flash-live-001 Model(name='models/gemini-2.0-flash-live-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 2.0 Flash 001',\n",
      "      description='Gemini 2.0 Flash 001',\n",
      "      input_token_limit=131072,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-live-2.5-flash-preview Model(name='models/gemini-live-2.5-flash-preview',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini Live 2.5 Flash Preview',\n",
      "      description='Gemini Live 2.5 Flash Preview',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "models/gemini-2.5-flash-live-preview Model(name='models/gemini-2.5-flash-live-preview',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 2.5 Flash Live Preview',\n",
      "      description='Gemini 2.5 Flash Live Preview',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=65536,\n",
      "      supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# List all available models\n",
    "for m in genai.list_models():\n",
    "    print(m.name, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca3a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
